# -*- coding: utf-8 -*-
"""IR_Assignment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14ZVVMVXmBBnXHmw8f4Nv__WorhytTuuy
"""

from google.colab import drive
drive.mount('/content/drive')

pip install pandas numpy nltk Pillow requests tensorflow

import pandas as pd
import numpy as np
import requests
import json
from io import BytesIO
from PIL import Image, ImageEnhance
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import string
import math
import pickle
from collections import defaultdict
from numpy.linalg import norm

# Ensure necessary NLTK datasets are downloaded
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

import os
from PIL import Image, ImageEnhance
import numpy as np
from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input
from tensorflow.keras.models import Model
import pickle
import pandas as pd

# Initialize the InceptionV3 model globally
inception_model = InceptionV3(weights='imagenet', include_top=False)
model = Model(inputs=inception_model.input, outputs=inception_model.output)

def preprocess_and_extract_features(image_url):
    """Preprocess an image from a URL and extract features using InceptionV3."""
    try:
        response = requests.get(image_url)
        image = Image.open(BytesIO(response.content)).convert('RGB')
        image = image.resize((299, 299))
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.5)
        image_array = np.array(image)
        image_array = preprocess_input(image_array)
        image_array = np.expand_dims(image_array, axis=0)
        features = model.predict(image_array)
        return (image_url, features.reshape(features.shape[0], -1).tolist())
    except Exception as e:
        print(f"Error processing image from URL {image_url}: {e}")
        return (image_url, None)

def preprocess_text(text):
    """Lowercase, remove punctuation, tokenize, remove stopwords, and lemmatize text."""
    text = text.lower().translate(str.maketrans('', '', string.punctuation))
    tokens = nltk.word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]
    return ' '.join(tokens)

def compute_tf(text):
    """Compute term frequency for a document."""
    words = text.split()
    tf = defaultdict(int)
    for word in words:
        tf[word] += 1
    return {word: count / len(words) for word, count in tf.items()}

def compute_idf(documents):
    """Compute inverse document frequency for all documents."""
    N = len(documents)
    idf = defaultdict(int)
    for doc in documents:
        for word in set(doc.split()):
            idf[word] += 1
    return {word: math.log(N / (idf[word] + 1)) for word in idf}

def compute_tfidf(documents):
    """Compute TF-IDF for all documents."""
    idf = compute_idf(documents)
    return [{word: tf * idf[word] for word, tf in compute_tf(doc).items()} for doc in documents]

def save_data(data, file_name):
    """Save data to a file using pickle."""
    with open(file_name, 'wb') as file:
        pickle.dump(data, file)

if __name__ == "__main__":
    # Example DataFrame loading and processing
    df = pd.read_csv('/content/drive/MyDrive/IR_Assignments/Assignment_2/A2_Data.csv')
    df['Image'] = df['Image'].apply(lambda x: json.loads(x.replace("'", "\""))[0] if x else None)

    # Process images and text
    image_features_with_url = [preprocess_and_extract_features(url) for url in df['Image']]


    # Save the results
    save_data(image_features_with_url, '/content/drive/MyDrive/IR_Assignments/Assignment_2/image_features.pkl')

    composite_data = []

    for index, row in df.iterrows():
        image_url = row['Image']
        review_text = row['Review Text']

        # Process image and text
        image_features = preprocess_and_extract_features(image_url)
        preprocessed_review = preprocess_text(review_text)
        tfidf_scores = compute_tfidf([preprocessed_review])[0]

        composite_data.append({
            'image_url': image_url,
            'review_text': review_text,  # Save the main review text
            'preprocessed_review': preprocessed_review,
            'tfidf_score': tfidf_scores
        })

    save_data(composite_data, '/content/drive/MyDrive/IR_Assignments/Assignment_2/composite_data.pkl')

from keras.applications.inception_v3 import InceptionV3, preprocess_input
from keras.models import Model
import requests
from PIL import Image, ImageEnhance
from io import BytesIO
import numpy as np
import pickle
import string
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from collections import defaultdict
import math

# Initialize InceptionV3 model globally to avoid reloading

inception_model = InceptionV3(weights='imagenet', include_top=False)
layer_name = 'mixed10'  # Example layer name, adjust based on actual investigation
model = Model(inputs=inception_model.input, outputs=inception_model.get_layer(layer_name).output)

def preprocess_and_extract_features(image_url):
    """Preprocess an image from a URL and extract features using InceptionV3."""
    try:
        response = requests.get(image_url)
        image = Image.open(BytesIO(response.content)).convert('RGB')
        image = image.resize((299, 299)) # InceptionV3 requires input images to be 299x299 pixels
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.5)
        image_array = np.array(image)
        image_array = preprocess_input(image_array)
        image_array = np.expand_dims(image_array, axis=0)
        features = model.predict(image_array)
        # Normalize features
        features = features / np.linalg.norm(features)
        return (image_url, features.reshape(features.shape[0], -1).tolist())
    except Exception as e:
        print(f"Error processing image from URL {image_url}: {e}")
        return (image_url, None)

def preprocess_text(text):
    """Lowercase, remove punctuation, tokenize, remove stopwords, and lemmatize text."""
    text = text.lower().translate(str.maketrans('', '', string.punctuation))
    tokens = nltk.word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]
    return ' '.join(tokens)

def compute_tf(text):
    """Compute term frequency for a document."""
    words = text.split()
    tf = defaultdict(int)
    for word in words:
        tf[word] += 1
    return {word: count / len(words) for word, count in tf.items()}

def compute_idf(documents):
    """Compute inverse document frequency for all documents."""
    N = len(documents)
    idf = defaultdict(int)
    for doc in documents:
        for word in set(doc.split()):
            idf[word] += 1
    return {word: math.log(N / (idf[word] + 1)) for word in idf}

def compute_tfidf(documents):
    """Compute TF-IDF for all documents."""
    idf = compute_idf(documents)
    return [{word: tf * idf[word] for word, tf in compute_tf(doc).items()} for doc in documents]

def save_data(data, file_name):
    """Save data to a file using pickle."""
    with open(file_name, 'wb') as file:
        pickle.dump(data, file)

def cosine_similarity(features_a, features_b):
    """Compute cosine similarity for higher-dimensional numpy arrays."""
    # Flatten the features only for the purpose of dot product calculation
    features_a_flat = features_a.flatten()
    features_b_flat = features_b.flatten()

    # Ensure normalization
    features_a_norm = features_a_flat / np.linalg.norm(features_a_flat)
    features_b_norm = features_b_flat / np.linalg.norm(features_b_flat)

    dot_product = np.dot(features_a_norm, features_b_norm)
    return dot_product  # Since vectors are normalized, no need to divide by norms again


def cosine_similarity_text(vec_a, vec_b):
    """Compute cosine similarity for dictionaries (TF-IDF vectors)."""
    if isinstance(vec_a, dict) and isinstance(vec_b, dict):
        intersection = set(vec_a.keys()) & set(vec_b.keys())
        numerator = sum([vec_a[x] * vec_b[x] for x in intersection])
        sum1 = sum([val**2 for val in vec_a.values()])
        sum2 = sum([float(val)**2 for val in vec_b.values()])
        denominator = np.sqrt(sum1) * np.sqrt(sum2)
        return float(numerator) / denominator if denominator != 0 else 0.0
    else:
        raise ValueError("TF-IDF vectors must be of type dict.")

def find_most_similar(features_with_url, input_features, top_k=3):
    """Find the top k most similar items based on cosine similarity."""
    similarities = []
    for url, features in features_with_url:
        if features is not None:
            sim = cosine_similarity(input_features, np.array(features))
            similarities.append((url, sim))
    similarities.sort(key=lambda x: x[1], reverse=True)
    return similarities[:top_k]

def find_most_similar_reviews(composite_data, input_tfidf, top_k=3):
    """Find and rank reviews based on text similarity."""
    similarities = []
    for item in composite_data:
        sim = cosine_similarity_text(input_tfidf, item['tfidf_score'])
        similarities.append((item['image_url'], sim, item['preprocessed_review']))
    similarities.sort(key=lambda x: x[1], reverse=True)
    return similarities[:top_k]

def save_results(filename, data):
    """Save data to a pickle file."""
    with open(filename, 'wb') as file:
        pickle.dump(data, file)

def load_data(image_features_file, composite_data_file):
    """Load image features and composite data from pickle files."""
    with open(image_features_file, 'rb') as f:
        image_features_with_url = pickle.load(f)
    with open(composite_data_file, 'rb') as f:
        composite_data = pickle.load(f)
    return image_features_with_url, composite_data

def process_input(image_url, review_text):
    """Preprocess and compute features for input image and review text."""
    _, input_image_features = preprocess_and_extract_features(image_url)
    input_review_tfidf = compute_tfidf([preprocess_text(review_text)])[0]
    return np.array(input_image_features), input_review_tfidf

def print_results(results, result_type):
    """Print sorted results for image and text retrieval."""
    print(f"USING {result_type.upper()} RETRIEVAL")
    for idx, (img_url, review, img_sim, text_sim, composite_similarity) in enumerate(results, start=1):
        print(f"{idx}) Image URL: {img_url}\nReview: {review}\nCosine similarity of images: {img_sim:.4f}\nCosine similarity of text: {text_sim:.4f}\nComposite similarity score: {composite_similarity:.4f}\n")

def main():
    image_url = input("Enter the image URL: ")
    review_text = input("Enter the review text: ")

    # Load pre-computed data
    image_features_with_url, composite_data = load_data(
        '/content/drive/MyDrive/IR_Assignments/Assignment_2/image_features.pkl',
        '/content/drive/MyDrive/IR_Assignments/Assignment_2/composite_data.pkl'
    )

    # Process input
    input_image_features, input_review_tfidf = process_input(image_url, review_text)

    # Retrieve similar images and reviews
    similar_images = find_most_similar(image_features_with_url, input_image_features, top_k=3)
    similar_reviews = find_most_similar_reviews(composite_data, input_review_tfidf, top_k=3)

    # Save retrieval results
    save_results('/content/drive/MyDrive/IR_Assignments/Assignment_2/similar_images.pkl', similar_images)
    save_results('/content/drive/MyDrive/IR_Assignments/Assignment_2/similar_reviews.pkl', similar_reviews)

    # Calculate and sort composite results for both image and text retrieval
    composite_results_image = calculate_composite_scores(similar_images, composite_data, input_review_tfidf, input_image_features, mode="image")
    composite_results_text = calculate_composite_scores(similar_reviews, composite_data, input_review_tfidf, input_image_features, mode="text")

    # Print sorted results
    print_results(composite_results_image, "image")
    print_results(composite_results_text, "text")

def calculate_composite_scores(similar_items, composite_data, input_tfidf, input_features, mode="image"):
    """Calculate composite similarity scores for either images or text."""
    composite_results = []
    for item in similar_items:
        img_url = item[0] if mode == "image" else item[2]  # URL is in different positions based on mode
        sim_score = item[1] if mode == "image" else item[3]  # Similarity score position varies
        review_data = next((data for data in composite_data if data['image_url'] == img_url), None)
        
        if review_data:
            img_features = next((features for url, features in image_features_with_url if url == img_url), None)
            img_sim = cosine_similarity(input_features, np.array(img_features)) if img_features is not None else 0
            text_sim = cosine_similarity_text(input_tfidf, review_data['tfidf_score'])
            composite_similarity = (img_sim + text_sim) / 2
            composite_results.append((img_url, review_data['review_text'], img_sim, text_sim, composite_similarity))
        else:
            # For items without matching composite data
            composite_results.append((img_url, "Review not found", sim_score, 0, sim_score / 2))
    
    composite_results.sort(key=lambda x: x[4], reverse=True)
    return composite_results

if __name__ == "__main__":
    main()

import pickle

def load_data(file_name):
    """Load serialized data from a file."""
    with open(file_name, 'rb') as file:
        return pickle.load(file)

# Specify the paths to your files
image_features_path = '/content/drive/MyDrive/IR_Assignments/Assignment_2/image_features.pkl'
similar_REVIEWS ='/content/drive/MyDrive/IR_Assignments/Assignment_2/similar_reviews.pkl'
similar_IMAGES ='/content/drive/MyDrive/IR_Assignments/Assignment_2/similar_images.pkl'



# Load the data
image_features = load_data(image_features_path)
images=load_data(similar_IMAGES)
review=load_data(similar_REVIEWS)

# Print the contents

print("Image Features (first item):", image_features[0][:10])  # Print first 10 features of the first item
print(review)
print(images)
